{"cells":[{"cell_type":"markdown","metadata":{"id":"D5y90GLVXafO"},"source":["## Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98fVt3W9W9Cg"},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1J33A8-Jlw3i"},"outputs":[],"source":["!pip install -q -U segmentation-models-pytorch albumentations > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2841,"status":"ok","timestamp":1689915953902,"user":{"displayName":"조영민","userId":"10749653391039175177"},"user_tz":-540},"id":"gYR8dMIJYIV4","outputId":"6a687410-b39c-4154-93e0-37649e89f0d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/sw_contest\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/sw_contest\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5165,"status":"ok","timestamp":1689915959065,"user":{"displayName":"조영민","userId":"10749653391039175177"},"user_tz":-540},"id":"XS-Ucq5oZSOP","outputId":"29f0d0f9-986f-4cb3-97ff-a3398686452a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.74)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n"]}],"source":["!pip install --upgrade opencv-python"]},{"cell_type":"markdown","metadata":{"id":"20x7C0trXd_p"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZyppwFOXZxA"},"outputs":[],"source":["# RLE 디코딩 함수\n","def rle_decode(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"markdown","metadata":{"id":"qThRcQtbXhpr"},"source":["## Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-tXvlsMXaLV"},"outputs":[],"source":["class SatelliteDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_rle = self.data.iloc[idx, 2]\n","        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","\n","        if self.transform:\n","\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask"]},{"cell_type":"markdown","metadata":{"id":"R7L-fVpTXnk8"},"source":["## Data Loader"]},{"cell_type":"markdown","metadata":{"id":"dYtk8cmVSxyv"},"source":["crop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpuDuZr6SoYI"},"outputs":[],"source":["train_df = pd.read_csv(\"./train.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SykWkSRXSy70"},"outputs":[],"source":["def crop_img(img, img_size=256):\n","    img_list = []\n","\n","    y_cnt = 0\n","    while True:\n","        start_y = y_cnt * img_size\n","        end_y = (y_cnt + 1) * img_size\n","\n","        if end_y > 1024:\n","            break\n","\n","        x_cnt = 0\n","        while True:\n","            start_x = x_cnt * img_size\n","            end_x = (x_cnt + 1) * img_size\n","\n","            if end_x > 1024:\n","                break\n","\n","            temp_img = img[start_x:end_x, start_y:end_y, :]\n","            x_cnt += 1\n","            img_list.append(temp_img)\n","\n","        y_cnt += 1\n","\n","    return img_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ReEdn3gS-9K","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"error","timestamp":1689819321872,"user_tz":-540,"elapsed":9,"user":{"displayName":"박혜현","userId":"01280441086810095910"}},"outputId":"d94263bc-bb32-4c25-97c3-0fe28f044b61"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-343e993f350c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-a155bdbdff9a>\u001b[0m in \u001b[0;36mcrop_img\u001b[0;34m(img, img_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtemp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mx_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mimg_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["# new_data_list = []\n","# for idx, row in train_df.iterrows():\n","#     img_name = row[\"img_path\"].split(\"/\")[-1]\n","#     img_path = os.path.join(\".\", img_name)\n","\n","#     img = cv2.imread(img_path)\n","\n","#     images = crop_img(img)\n","#     masks = crop_img(mask)\n","\n","#     for idx, (img, mask) in enumerate(zip(images, masks)):\n","#         new_img_name = img_name[:-4] + \"_\" + str(idx).zfill(2) + \".png\"\n","#         new_data_list.append({\"img_id\": new_img_name[:-4]})\n","\n","#         cv2.imwrite(os.path.join(\"./train_img_crop\", new_img_name), img)\n"]},{"cell_type":"markdown","metadata":{"id":"8s3oBdiISzkf"},"source":["normal augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1833,"status":"ok","timestamp":1689915969458,"user":{"displayName":"조영민","userId":"10749653391039175177"},"user_tz":-540},"id":"MMKF4OxNPLRy","outputId":"3daf01b3-9d8d-4c90-c078-445f349abef8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n","  warnings.warn(\n"]}],"source":["def train_transform(train = True):\n","        return A.Compose(\n","            [\n","                A.OneOf(\n","                    [\n","                        A.RandomBrightness(p=1),\n","                        A.RandomBrightnessContrast(p=1),\n","                        A.Emboss(p=1),\n","                        A.RandomShadow(p=1),\n","                        A.NoOp(),\n","                    ],\n","                    p=1,\n","                ),\n","                A.OneOf(\n","                    [\n","                        A.Blur(p=1),\n","                        A.AdvancedBlur(p=1),\n","                        A.MotionBlur(p=1),\n","                    ],\n","                    p=0.6,\n","                ),\n","                A.OneOf(\n","                    [\n","                        A.NoOp(),\n","                        A.HorizontalFlip(p=0.5),\n","                        A.VerticalFlip(p=0.5),\n","                        A.ShiftScaleRotate(p=0.5),\n","                        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_REPLICATE),\n","                        A.RandomRotate90(p=1)\n","                    ],\n","                    p=1,\n","                ),\n","                A.RandomCrop(224, 224),\n","                A.Normalize(),\n","                ToTensorV2(transpose_mask=True)\n","            ]\n","        )\n","\n","\n","def test_transform():\n","        return A.Compose(\n","            [\n","                A.Normalize(),\n","                ToTensorV2(transpose_mask=True)\n","            ]\n","        )\n","\n","train_transform = train_transform()\n","test_transform = test_transform()\n","\n","dataset = SatelliteDataset(csv_file='./train.csv', transform=train_transform)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"3MCnYsZ6Xrj9"},"source":["## Define Model"]},{"cell_type":"markdown","metadata":{"id":"ieaEZlCGXwhS"},"source":["## Model Train"]},{"cell_type":"markdown","metadata":{"id":"bTWv6c9gH_dM"},"source":["DeepLabV3Plus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"19c0yQ9Pfc-7","outputId":"45893447-e042-42a7-bbb6-ccc97043f633","executionInfo":{"status":"error","timestamp":1689916047418,"user_tz":-540,"elapsed":61407,"user":{"displayName":"조영민","userId":"10749653391039175177"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  2%|▏         | 4/224 [00:52<47:43, 13.02s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6a817c394b06>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model 초기화\n","import segmentation_models_pytorch as smp\n","\n","lr = 1e-4\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_epochs = 1\n","\n","num_classes = 2\n","\n","# 전이 학습에 사용할 미리 학습된 DeepLabV3Plus 모델 가져오기\n","model = smp.DeepLabV3Plus(encoder_name=\"resnet101\", encoder_weights=\"imagenet\", in_channels=3, classes=num_classes)\n","\n","\n","# 모델을 GPU로 이동\n","model.to(device)\n","\n","\n","v3plus_weight = torch.load(\"./weights/v3plus_11.pth\")\n","model.load_state_dict(v3plus_weight, strict=False)\n","# v3plus_weight = torch.load(\"./songweights/v3plus3_30.pth\")\n","# model.load_state_dict(v3plus_weight,strict=False)\n","\n","# loss function과 optimizer 정의\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr)\n","\n","# training loop\n","for epoch in range(num_epochs):  # 30 에폭 동안 학습합니다.\n","    model.train()\n","    epoch_loss = 0\n","    for images, masks in tqdm(dataloader):\n","        images = images.to(device)\n","        masks = masks.to(device)\n","        masks = masks.long()\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","   # if (epoch+1)%10 == 0:\n","    torch.save(model.state_dict(), './weights/v3plus_' + str(epoch+1+11) + '.pth')\n","\n","\n","    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n"]},{"cell_type":"markdown","metadata":{"id":"yDjG-j_8IKby"},"source":["UnetPlusPlus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"3estbjhGIEge","outputId":"c78e336a-0adf-49b8-a42f-390361ce623c","executionInfo":{"status":"error","timestamp":1689916110735,"user_tz":-540,"elapsed":53103,"user":{"displayName":"조영민","userId":"10749653391039175177"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  1%|▏         | 3/224 [00:51<1:03:14, 17.17s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-12224a090900>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model 초기화\n","import segmentation_models_pytorch as smp\n","\n","lr = 1e-4\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_epochs = 21\n","\n","num_classes = 2\n","\n","# 전이 학습에 사용할 미리 학습된 DeepLabV3Plus 모델 가져오기\n","model2 = smp.UnetPlusPlus(encoder_name=\"resnet101\", encoder_weights=\"imagenet\", in_channels=3, classes=num_classes)\n","\n","\n","# 모델을 GPU로 이동\n","model2.to(device)\n","\n","# v3plus_weight = torch.load(\"./songweights/v3plus3_30.pth\")\n","# model.load_state_dict(v3plus_weight,strict=False)\n","\n","# loss function과 optimizer 정의\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model2.parameters(), lr)\n","\n","# training loop\n","for epoch in range(num_epochs):  # 30 에폭 동안 학습합니다.\n","    model2.train()\n","    epoch_loss = 0\n","    for images, masks in tqdm(dataloader):\n","        images = images.to(device)\n","        masks = masks.to(device)\n","        masks = masks.long()\n","\n","        optimizer.zero_grad()\n","        outputs = model2(images)\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    if (epoch+1)%10 == 1:\n","      torch.save(model2.state_dict(), './JOngweights/unetplus_' + str(epoch+1) + '.pth')\n","\n","\n","    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n"]},{"cell_type":"markdown","metadata":{"id":"FlOIJsvVXzY_"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LN86qyD0X20V"},"outputs":[],"source":["# with torch.no_grad():\n","#     model.eval()\n","#     result = []\n","#     for images in tqdm(test_dataloader):\n","#         images = images.float().to(device)\n","\n","#         outputs = model(images)\n","#         masks = torch.sigmoid(outputs).cpu().numpy()\n","#         masks = np.squeeze(masks, axis=1)\n","#         masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n","\n","#         for i in range(len(images)):\n","#             mask_rle = rle_encode(masks[i])\n","#             if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","#                 result.append(-1)\n","#             else:\n","#                 result.append(mask_rle)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwtokDRP24Jc","outputId":"3f6b60b8-adf6-4377-d31c-5f21f771f436","executionInfo":{"status":"ok","timestamp":1689925483147,"user_tz":-540,"elapsed":9368570,"user":{"displayName":"조영민","userId":"10749653391039175177"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1895/1895 [2:36:04<00:00,  4.94s/it]\n"]}],"source":["v3plus_weight = torch.load(\"./weights/v3plus_21.pth\")\n","model.load_state_dict(v3plus_weight, strict=False)\n","\n","unetplus_weight = torch.load(\"./weights/unetplus_21_song.pth\")\n","model2.load_state_dict(unetplus_weight, strict=False)\n","\n","test_dataset = SatelliteDataset(csv_file='./test.csv', transform=test_transform, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","with torch.no_grad():\n","    model.eval()\n","    model2.eval()\n","    result = []\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","\n","        outputs1 = model(images)\n","        masks1 = torch.sigmoid(outputs1).cpu().numpy()\n","\n","        outputs2 = model2(images)\n","        masks2 = torch.sigmoid(outputs2).cpu().numpy()\n","\n","        # 예측 결과를 보팅 결과에 추가\n","        voting_results = []\n","        for i in range(len(images)):\n","            mask1 = (masks1[i] > 0.35).astype(np.uint8)  # 임계값 = 0.35\n","            mask2 = (masks2[i] > 0.35).astype(np.uint8)  # 임계값 = 0.35\n","\n","            # 두 모델의 예측을 모두 사용하여 보팅을 수행\n","            combined_votes = mask1 + mask2\n","            final_mask = (combined_votes >= 2).astype(np.uint8)  # 두 모델이 동일하게 예측한 부분만 선택\n","            mask_rle = rle_encode(final_mask)\n","            result.append(mask_rle)\n","\n","submit = pd.read_csv('./sample_submission.csv')\n","submit['mask_rle'] = result\n","submit.to_csv(\"submission_ensemble.csv\", index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"EFUSJ285X4ne"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZcUbNV8X5-W"},"outputs":[],"source":["submit = pd.read_csv('./sample_submission_song.csv')\n","submit['mask_rle'] = result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ke8fygMX7i4"},"outputs":[],"source":["submit.to_csv('./submit_deeplabveplus_resnet101_epoch30.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8ZSgkx8iw68","outputId":"398fb29c-a635-4eea-9ea5-efaa5adc4beb","executionInfo":{"status":"ok","timestamp":1689925937132,"user_tz":-540,"elapsed":1676,"user":{"displayName":"조영민","userId":"10749653391039175177"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of rows with -1 in 'mask_rle' column: 15429\n"]}],"source":["import pandas as pd\n","\n","# CSV 파일을 읽어와 DataFrame에 저장\n","csv_file_path = './submission_ensemble.csv'  # CSV 파일의 경로를 지정해야 합니다.\n","df = pd.read_csv(csv_file_path)\n","\n","# 'mask_rle' 열에서 -1인 행의 총 수를 출력\n","count_minus_1 = df['mask_rle'].eq('1 50176').sum()\n","\n","print(\"Total number of rows with -1 in 'mask_rle' column:\", count_minus_1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8JAbnJYjfwp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}